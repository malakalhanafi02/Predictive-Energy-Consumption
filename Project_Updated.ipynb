{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "soj3B63dYSPv",
    "outputId": "8a48641c-4032-4506-dafe-f4b8b21ba137"
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo # Used to import the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Models import *\n",
    "\n",
    "# fetch dataset\n",
    "dataset = fetch_ucirepo(id=235)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X_data = dataset.data.features\n",
    "y_data = dataset.data.targets\n",
    "\n",
    "# metadata\n",
    "print(dataset.metadata)\n",
    "\n",
    "# variable information\n",
    "print(dataset.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYfbXfegYSPy"
   },
   "outputs": [],
   "source": [
    "X = X_data.copy(deep=True)\n",
    "categories = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "X[categories] = X[categories].apply(pd.to_numeric, errors='coerce')\n",
    "for cat in categories:\n",
    "    X[cat] = X[cat].interpolate()\n",
    "\n",
    "np.sum(np.isnan(X['Global_active_power']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify where the values are NaN\n",
    "is_nan = np.isnan(X['Global_active_power'])\n",
    "\n",
    "# Find where the NaN sequences start and end\n",
    "nan_runs = np.diff(np.concatenate(([0], is_nan.astype(int), [0])))\n",
    "start_indices = np.where(nan_runs == 1)[0]\n",
    "end_indices = np.where(nan_runs == -1)[0]\n",
    "\n",
    "# Calculate the lengths of each run\n",
    "nan_lengths = end_indices - start_indices\n",
    "\n",
    "# Filter runs with more than 5 NaNs\n",
    "long_nan_runs = [(start, length) for start, length in zip(start_indices, nan_lengths) if length > 5]\n",
    "\n",
    "print(long_nan_runs)\n",
    "\n",
    "X['Date'][190497+3723], X['Date'][1309386]\n",
    "X['Date'][0], X['Date'][len(X)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "KD1NR5wvYSPz",
    "outputId": "6b6a773e-654d-490f-845a-e3c40449b57b"
   },
   "outputs": [],
   "source": [
    "PF = np.cos(np.arctan(X['Global_reactive_power'] / X['Global_active_power']))\n",
    "X.insert(4, 'Power_factor', PF, True)\n",
    "X.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Power_factor'].quantile(q=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "e2jC39doYSPz",
    "outputId": "f5a7117a-f29c-4cbc-f7c0-a102779d6a26"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Adjust Date_Time column for sensible plots\n",
    "DateTime = X['Date'].str.cat(X['Time'].values.astype(str), sep=' ')\n",
    "X.insert(0, 'Date_Time', DateTime, True) #includes Date_time variable\n",
    "X = X.drop('Date', axis=1) #removes date column\n",
    "X = X.drop('Time', axis=1) #removes time column\n",
    "X.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE = X['Global_active_power']*(1000/60) - X['Sub_metering_1'] - X['Sub_metering_2'] - X['Sub_metering_3']\n",
    "X.insert(1, 'GAE', GAE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "zS_uPq9WDiU7",
    "outputId": "3d0621ba-527a-4847-c5b1-6f8964e8a48f"
   },
   "outputs": [],
   "source": [
    "X.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Qk22wMmzC6k",
    "outputId": "7b06abff-f6f2-4324-e230-b99686d6ece1"
   },
   "outputs": [],
   "source": [
    "# Define categories for each figure\n",
    "fig1_categories = ['Global_active_power', 'Global_reactive_power', 'Power_factor']\n",
    "fig2_categories = ['GAE']\n",
    "fig3_categories = ['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "fig4_categories = ['Voltage', 'Global_intensity']\n",
    "\n",
    "# Helper function to create and format each figure\n",
    "def create_figure(categories, fig_title):\n",
    "    fig, axes = plt.subplots(len(categories), figsize=(15, 6 * len(categories)))\n",
    "    fig.suptitle(fig_title, fontsize=16)\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        ax = axes[i] if len(categories) > 1 else axes\n",
    "        ax.plot(X['Date_Time'], X[category], label=category)\n",
    "        ax.set_title(category)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel(category)\n",
    "        ax.legend()\n",
    "\n",
    "        # Set the number of x-axis ticks to 12 and rotate labels\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(13))\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Set the number of y-axis ticks to 5\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(5))\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Create each figure based on the planned categories\n",
    "create_figure(fig1_categories, 'Figure 1: Global Active Power, Global Reactive Power, Power Factor')\n",
    "create_figure(fig2_categories, 'Figure 2: Global Active Energy (GAE)')\n",
    "create_figure(fig3_categories, 'Figure 3: Sub Meterings 1-3')\n",
    "create_figure(fig4_categories, 'Figure 4: Voltage and Current (Global Intensity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9pho780CrEm5",
    "outputId": "ce1c4e1b-014f-441f-bcb7-34becc81de5e"
   },
   "outputs": [],
   "source": [
    "# Create plots for each category\n",
    "fig, axes = plt.subplots(8, figsize=(15, 20))\n",
    "fig.suptitle('First 3 Days of Each Category vs Time [Reduced Dataset]', fontsize=16)\n",
    "\n",
    "category = ['GAE', 'Global_active_power', 'Global_reactive_power','Power_factor', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "\n",
    "# Plot each category\n",
    "for i, category in enumerate(category):\n",
    "    ax = axes[i]\n",
    "    ax.plot(X['Date_Time'], X[category], label=category)\n",
    "    ax.set_title(category)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel(category)\n",
    "    ax.legend()\n",
    "\n",
    "    # Limit the number of x-axis ticks to avoid clutter\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))  # Adjust the number as needed\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    # Cast y_true to float32 to ensure type consistency\n",
    "    y_true = K.cast(y_true, dtype='float32')\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return 1 - ss_res / (ss_tot + K.epsilon())\n",
    "\n",
    "# Preprocessing function for Date_Time\n",
    "def preprocess_datetime(data):\n",
    "    \"\"\"\n",
    "    Converts 'Date_Time' strings to Unix timestamps.\n",
    "    Adjust the format string to match your datetime format.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        datetime.strptime(dt, '%d/%m/%Y %H:%M:%S').timestamp() for dt in data\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "def train_test_split(data, categories: list, predictors:str, split=0.8):\n",
    "    \"\"\"\n",
    "    Splits the given data into train and test sets.\n",
    "    \"\"\"\n",
    "    split_int = int(len(data) * split)\n",
    "    X_train, X_test = np.array(data[categories][:split_int]), np.array(data[categories][split_int:])\n",
    "    y_train, y_test = np.array(data[predictors][:split_int]), np.array(data[predictors][split_int:])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ['Voltage', 'Global_intensity', 'Power_factor'], \n",
    "                                                    ['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3'], 0.8)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_processed = scaler.fit_transform(X_train)\n",
    "X_test_processed = scaler.transform(X_test)\n",
    "\n",
    "# Generator for windowed data\n",
    "def create_windowed_batches(X_data, y_data, window_size, batch_size, stride=1):\n",
    "    \"\"\"\n",
    "    Generator to create batches of windowed data.\n",
    "    \"\"\"\n",
    "    total_windows = (len(X_data) - window_size) // stride\n",
    "    while True:\n",
    "        for i in range(0, total_windows, batch_size):\n",
    "            X_batch, y_batch = [], []\n",
    "            for j in range(i, min(i + batch_size, total_windows)):\n",
    "                start = j * stride\n",
    "                X_batch.append(X_data[start:start + window_size])\n",
    "                y_batch.append(y_data[start + window_size])\n",
    "            yield np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "# Define parameters\n",
    "window_size = 60\n",
    "batch_size = 1024\n",
    "stride = 1\n",
    "\n",
    "# Create training and validation generators\n",
    "train_gen = create_windowed_batches(X_train_processed, y_train, window_size, batch_size, stride)\n",
    "val_gen = create_windowed_batches(X_test_processed, y_test, window_size, batch_size, stride)\n",
    "\n",
    "# Calculate the number of steps per epoch\n",
    "train_steps_per_epoch = (len(X_train_processed) - window_size) // stride // batch_size\n",
    "val_steps_per_epoch = (len(X_test_processed) - window_size) // stride // batch_size\n",
    "\n",
    "layer_list = [\n",
    "    'LSTM(128)', 'Dropout(0.1)', \n",
    "    'LSTM(64)', 'Dropout(0.1)', \n",
    "    32, 3\n",
    "]\n",
    "input_shape = (window_size, X_train_processed.shape[1])\n",
    "\n",
    "# model = build_rnn(layer_list, input_shape)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(window_size, X_train_processed.shape[1]), return_sequences=True),\n",
    "    Dropout(0.1),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Single output (regression task)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[MeanAbsoluteError(), r2_score])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=50,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def create_windows(X_data, y_data, window_size, stride=1):\n",
    "    \"\"\"\n",
    "    Create fixed-size windows for evaluation.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(X_data) - window_size, stride):\n",
    "        X.append(X_data[i:i + window_size])\n",
    "        y.append(y_data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_test_windowed, y_test_windowed = create_windows(X_test_processed, y_test, window_size, stride=1)\n",
    "test_loss, test_mae, test_r2 = model.evaluate(X_test_windowed, y_test_windowed, verbose=1)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test R2: {test_r2}\")\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot MAE\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
